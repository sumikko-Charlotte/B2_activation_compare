实验思想日志（最终版 v3）
一、最初的想法

在刚开始做这个实验时，我对激活函数的理解比较直观，只知道它们的作用是为神经网络引入非线性，使模型不再等价于线性分类器。我最初的判断是：ReLU 在深度学习中应用非常广泛，因此在实验中应该表现最好。

在数据集选择上，我选择了 make_moons，因为它是一个典型的非线性可分数据集，且只有二维特征，便于通过可视化来观察模型的分类效果。这一选择的初衷是希望通过一个“足够简单但又必须使用非线性模型”的任务，来突出激活函数的作用差异。

二、实验过程中遇到的问题与调整

在实验实现过程中，我逐渐发现一些之前没有考虑到的问题。

首先是实验可复现性问题。一开始我没有固定随机种子，导致每次运行结果（准确率和 loss 曲线）都会发生变化，这让我很难判断不同激活函数之间的真实差异。后来在反思后意识到，实验对比的前提是控制变量，因此在最终版本中统一设置了随机种子，以保证结果具有可复现性。

其次是在训练过程可视化方面。最初我只关注最终的验证准确率，但在绘制 loss 曲线后发现，不同激活函数在收敛速度和稳定性上存在明显差异。例如 Sigmoid 的 loss 下降较慢，且在前期震荡明显，这一现象促使我进一步思考激活函数梯度特性的影响。

此外，在多种激活函数的对比中，如果只给出数值结果（如准确率），结论仍然较为抽象。因此在最终版本中，我增加了决策边界可视化，从几何角度观察模型对非线性数据的拟合能力，这也显著提升了实验的解释性。

三、对大模型预测的怀疑与反思

在实验开始前，大模型预测 ReLU 会取得最好的效果。但在实际实验中我发现，对于 make_moons 这样规模较小、结构相对简单的数据集，不同激活函数之间的性能差距并不像预期那样悬殊。

例如，Tanh 在某些实验中表现与 ReLU 接近，而 Sigmoid 虽然收敛较慢，但最终仍能得到可接受的分类效果。这让我意识到，大模型给出的结论往往基于更复杂、更大规模任务的经验总结，而在具体实验场景下，数据集本身的结构和难度会对结论产生重要影响。

通过引入决策边界可视化，我更加直观地理解了这一点：
Identity 激活函数几乎只能形成线性决策边界，无法正确划分月牙形数据；而 ReLU 和 Tanh 能够学习到弯曲的非线性边界。这一结果让我认识到，实验的价值不仅在于验证“谁更好”，更在于理解为什么某些方法在特定条件下会失败或成功。

四、实验带来的收获

通过本次实验，我从“验证模型效果”的角度，逐步转向“分析模型行为”的角度。相比单纯关注准确率，结合 loss 曲线和决策边界的分析，使我对激活函数在神经网络中的作用有了更加直观和深入的理解。

同时，这次实验也让我认识到，大模型给出的建议需要结合具体问题进行判断，不能直接照搬。只有通过实际实验和反思，才能真正理解理论与实践之间的关系。