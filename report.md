# Sklearn MLP 激活函数对比实验（大作业）

## 1. 项目简介
- 任务：对比 ReLU / Logistic(Sigmoid) / Tanh / Identity 在 MLP 上的表现
- 环境：Python + sklearn + matplotlib
- 数据集：make_moons（noise=0.2）

## 2. 三个版本迭代（v1 / v2 / v3）
### v1 初始版本：最小可行验证
- 主要问题：
- 下一步改进：
- 与大模型对话后的调整：

### v2 中期版本：多激活函数对比 + 可视化
- 主要问题：
- 下一步改进：
- 与大模型对话后的调整：

### v3 最终版本：可复现 + 深度解释
- 核心改进点：
- 最终结果总结：

## 3. 实验设置与理由
## 4. 实验结果展示与分析（图 + 解释）
## 5. 局限性与展望（为什么不用 torch + 未来如果用 torch 会怎样）
## 6. 参考与附录
- results/loss_curves.png
- results/summary.txt
- log.md / conversation.md
## 决策边界可视化分析（v3 核心改进）

通过对四种激活函数的决策边界进行可视化，可以直观地观察到不同激活函数对非线性数据的建模能力差异。

Identity 激活函数的决策边界接近线性，无法对 make_moons 数据集中的非线性结构进行有效划分；而 ReLU 和 Tanh 能够形成弯曲、复杂的分类边界，成功捕捉数据分布特征。这一结果从几何角度验证了“激活函数引入非线性”的理论结论。

相比仅观察准确率或 loss 曲线，决策边界图像能够更直观地展示模型学习过程，是本实验在最终版本（v3）中的关键改进。
由于实验重点在于激活函数本身对非线性分类能力的影响，而非深度框架工程实现，最终选择 sklearn 的 MLPClassifier 进行快速验证。其高度封装的特性有助于将注意力集中在实验设计与结果分析上，而非框架细节。